{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "P-JuIu2N_SQf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowjs\n",
      "  Using cached tensorflowjs-3.1.0-py3-none-any.whl (63 kB)\n",
      "Requirement already satisfied: tensorflow-hub<0.10,>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflowjs) (0.9.0)\n",
      "Requirement already satisfied: tensorflow<3,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflowjs) (2.4.1)\n",
      "Requirement already satisfied: six<2,>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflowjs) (1.15.0)\n",
      "Requirement already satisfied: h5py<3,>=2.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorflowjs) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /opt/conda/lib/python3.7/site-packages (from h5py<3,>=2.8.0->tensorflowjs) (1.19.5)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12.1)\n",
      "Collecting grpcio~=1.32.0\n",
      "  Using cached grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.14.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.4.1)\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.3.3)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.36.2)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.10.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.26.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (53.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.3)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (4.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (4.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.26.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.4.0)\n",
      "Installing collected packages: grpcio, tensorflowjs\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.35.0\n",
      "    Uninstalling grpcio-1.35.0:\n",
      "      Successfully uninstalled grpcio-1.35.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tfx 0.27.0 requires kubernetes<12,>=10.0.1, but you have kubernetes 12.0.1 which is incompatible.\n",
      "tfx 0.27.0 requires pyarrow<3,>=1, but you have pyarrow 3.0.0 which is incompatible.\n",
      "tensorflow-transform 0.27.0 requires pyarrow<3,>=1, but you have pyarrow 3.0.0 which is incompatible.\n",
      "tensorflow-model-analysis 0.27.0 requires pyarrow<3,>=1, but you have pyarrow 3.0.0 which is incompatible.\n",
      "tensorflow-data-validation 0.27.0 requires joblib<0.15,>=0.12, but you have joblib 1.0.1 which is incompatible.\n",
      "tensorflow-data-validation 0.27.0 requires pyarrow<3,>=1, but you have pyarrow 3.0.0 which is incompatible.\n",
      "explainable-ai-sdk 1.1.0 requires numpy<1.19.0, but you have numpy 1.19.5 which is incompatible.\n",
      "apache-beam 2.27.0 requires httplib2<0.18.0,>=0.8, but you have httplib2 0.19.0 which is incompatible.\n",
      "apache-beam 2.27.0 requires pyarrow<3.0.0,>=0.15.1, but you have pyarrow 3.0.0 which is incompatible.\u001b[0m\n",
      "Successfully installed grpcio-1.32.0 tensorflowjs-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflowjs as tfjs\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4fYMGxGhrna",
    "outputId": "e9762c48-ae8f-4a9f-d9d3-29a16abce1ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "NFC2ghIdiZYE"
   },
   "outputs": [],
   "source": [
    "def preprocess_images(images):\n",
    "  images = images.reshape((images.shape[0], 28, 28, 1)) / 255.\n",
    "  return np.where(images > .5, 1.0, 0.0).astype('float32')\n",
    "\n",
    "train_images = preprocess_images(train_images)\n",
    "test_images = preprocess_images(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "S4PIDhoDLbsZ"
   },
   "outputs": [],
   "source": [
    "train_size = 60000\n",
    "batch_size = 32\n",
    "test_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-yKCCQOoJ7cn"
   },
   "outputs": [],
   "source": [
    "train_dataset = (tf.data.Dataset.from_tensor_slices(train_images)\n",
    "                 .shuffle(train_size).batch(batch_size))\n",
    "test_dataset = (tf.data.Dataset.from_tensor_slices(test_images)\n",
    "                .shuffle(test_size).batch(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "VGLbvBEmjK0a"
   },
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "  \"\"\"Convolutional variational autoencoder.\"\"\"\n",
    "\n",
    "  def __init__(self, latent_dim):\n",
    "    super(CVAE, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            # No activation\n",
    "            tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Reshape(target_shape=(7, 7, 32)),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=32, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            # No activation\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=1, kernel_size=3, strides=1, padding='same'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "  @tf.function\n",
    "  def sample(self, eps=None):\n",
    "    if eps is None:\n",
    "      eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "    return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "  def encode(self, x):\n",
    "    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "    return mean, logvar\n",
    "\n",
    "  def reparameterize(self, mean, logvar):\n",
    "    eps = tf.random.normal(shape=mean.shape)\n",
    "    return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "  def decode(self, z, apply_sigmoid=False):\n",
    "    logits = self.decoder(z)\n",
    "    if apply_sigmoid:\n",
    "      probs = tf.sigmoid(logits)\n",
    "      return probs\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "iWCn_PVdEJZ7"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "  log2pi = tf.math.log(2. * np.pi)\n",
    "  return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x):\n",
    "  mean, logvar = model.encode(x)\n",
    "  z = model.reparameterize(mean, logvar)\n",
    "  x_logit = model.decode(z)\n",
    "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "  logpz = log_normal_pdf(z, 0., 0.)\n",
    "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "  \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "  This function computes the loss and gradients, and uses the latter to\n",
    "  update the model's parameters.\n",
    "  \"\"\"\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss = compute_loss(model, x)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "NS2GWywBbAWo"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "latent_dim = 2\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[num_examples_to_generate, latent_dim])\n",
    "model = CVAE(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "swCyrbqQQ-Ri"
   },
   "outputs": [],
   "source": [
    "# Pick a sample of the test set for generating output images\n",
    "assert batch_size >= num_examples_to_generate\n",
    "for test_batch in test_dataset.take(1):\n",
    "  test_sample = test_batch[0:num_examples_to_generate, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "2M7LmLtGEMQJ",
    "outputId": "2fb2b76a-496f-4bb4-9a2e-e460dcabf595"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Test set ELBO: -172.2581024169922, time elapse for current epoch: 4.588509559631348\n",
      "Epoch: 2, Test set ELBO: -167.8203582763672, time elapse for current epoch: 4.656669616699219\n",
      "Epoch: 3, Test set ELBO: -164.28297424316406, time elapse for current epoch: 4.639188289642334\n",
      "Epoch: 4, Test set ELBO: -162.1638946533203, time elapse for current epoch: 4.5886452198028564\n",
      "Epoch: 5, Test set ELBO: -160.04052734375, time elapse for current epoch: 4.629687070846558\n",
      "Epoch: 6, Test set ELBO: -158.94114685058594, time elapse for current epoch: 4.584612607955933\n",
      "Epoch: 7, Test set ELBO: -157.96498107910156, time elapse for current epoch: 4.6225855350494385\n",
      "Epoch: 8, Test set ELBO: -157.2873077392578, time elapse for current epoch: 4.658017158508301\n",
      "Epoch: 9, Test set ELBO: -156.52035522460938, time elapse for current epoch: 4.668649196624756\n",
      "Epoch: 10, Test set ELBO: -156.08035278320312, time elapse for current epoch: 4.584564924240112\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "  start_time = time.time()\n",
    "  for train_x in train_dataset:\n",
    "    train_step(model, train_x, optimizer)\n",
    "  end_time = time.time()\n",
    "\n",
    "  loss = tf.keras.metrics.Mean()\n",
    "  for test_x in test_dataset:\n",
    "    loss(compute_loss(model, test_x))\n",
    "  elbo = -loss.result()\n",
    "  print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "        .format(epoch, elbo, end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RUGPbACeet6q",
    "outputId": "6d5e248d-c0cf-496e-f673-ba852e294b01"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflowjs/converters/keras_h5_conversion.py:123: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  return h5py.File(h5file)\n"
     ]
    }
   ],
   "source": [
    "tfjs.converters.save_keras_model(model.encoder, 'encoder')\n",
    "tfjs.converters.save_keras_model(model.decoder, 'decoder')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cvae.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-4.mnightly-2021-02-12-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:mnightly-2021-02-12-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
