{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp.components import func_to_container_op, InputBinaryFile, OutputBinaryFile, OutputPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task(*args, **kwargs):\n",
    "    def decorator(f):\n",
    "        return func_to_container_op(f, *args, **kwargs)\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "zZWAwDlhKbF6"
   },
   "outputs": [],
   "source": [
    "@task(base_image='gcr.io/deeplearning-platform-release/tf2-cpu.2-4')\n",
    "def load_dataset(\n",
    "    train_images_file: OutputBinaryFile(),\n",
    "    test_images_file: OutputBinaryFile()):\n",
    "    \n",
    "  import numpy as np\n",
    "  import tensorflow as tf\n",
    "    \n",
    "  (train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()\n",
    "  np.save(train_images_file, train_images)\n",
    "  np.save(test_images_file, test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(base_image='gcr.io/deeplearning-platform-release/tf2-cpu.2-4')\n",
    "def preprocess_images(input_images_file: InputBinaryFile(), output_images_file: OutputBinaryFile()):\n",
    "  import numpy as np\n",
    "  images = np.load(input_images_file)\n",
    "  images = images.reshape((images.shape[0], 28, 28, 1)) / 255.\n",
    "  images = np.where(images > .5, 1.0, 0.0).astype('float32')\n",
    "  np.save(output_images_file, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(base_image='gcr.io/deeplearning-platform-release/tf2-cpu.2-4')\n",
    "def train(\n",
    "    epochs: int, \n",
    "    latent_dim: int, \n",
    "    train_size: int,\n",
    "    test_size: int,\n",
    "    batch_size: int,\n",
    "    train_images_file: InputBinaryFile(), \n",
    "    test_images_file: InputBinaryFile(), \n",
    "    output_path: OutputPath()):\n",
    "  \n",
    "  import json\n",
    "  import numpy as np\n",
    "  import tensorflow as tf\n",
    "  import time\n",
    "\n",
    "  class CVAE(tf.keras.Model):\n",
    "    \"\"\"Convolutional variational autoencoder.\"\"\"\n",
    "\n",
    "    def __init__(self, latent_dim):\n",
    "      super(CVAE, self).__init__()\n",
    "      self.latent_dim = latent_dim\n",
    "      self.encoder = tf.keras.Sequential(\n",
    "          [\n",
    "              tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
    "              tf.keras.layers.Conv2D(\n",
    "                  filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "              tf.keras.layers.Conv2D(\n",
    "                  filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "              tf.keras.layers.Flatten(),\n",
    "              # No activation\n",
    "              tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "          ]\n",
    "      )\n",
    "\n",
    "      self.decoder = tf.keras.Sequential(\n",
    "          [\n",
    "              tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "              tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
    "              tf.keras.layers.Reshape(target_shape=(7, 7, 32)),\n",
    "              tf.keras.layers.Conv2DTranspose(\n",
    "                  filters=64, kernel_size=3, strides=2, padding='same',\n",
    "                  activation='relu'),\n",
    "              tf.keras.layers.Conv2DTranspose(\n",
    "                  filters=32, kernel_size=3, strides=2, padding='same',\n",
    "                  activation='relu'),\n",
    "              # No activation\n",
    "              tf.keras.layers.Conv2DTranspose(\n",
    "                  filters=1, kernel_size=3, strides=1, padding='same'),\n",
    "          ]\n",
    "      )\n",
    "\n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "      if eps is None:\n",
    "        eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "      return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "    def encode(self, x):\n",
    "      mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "      return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "      eps = tf.random.normal(shape=mean.shape)\n",
    "      return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "      logits = self.decoder(z)\n",
    "      if apply_sigmoid:\n",
    "        probs = tf.sigmoid(logits)\n",
    "        return probs\n",
    "      return logits\n",
    "\n",
    "\n",
    "  def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(\n",
    "        -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "        axis=raxis)\n",
    "\n",
    "\n",
    "  def compute_loss(model, x):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_logit = model.decode(z)\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "  @tf.function\n",
    "  def train_step(model, x, optimizer):\n",
    "    \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "    This function computes the loss and gradients, and uses the latter to\n",
    "    update the model's parameters.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "      loss = compute_loss(model, x)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_images = np.load(train_images_file)\n",
    "  train_dataset = (tf.data.Dataset.from_tensor_slices(train_images)\n",
    "                  .shuffle(train_size).batch(batch_size))\n",
    "\n",
    "  test_images = np.load(test_images_file)\n",
    "  test_dataset = (tf.data.Dataset.from_tensor_slices(test_images)\n",
    "                  .shuffle(test_size).batch(batch_size))\n",
    "\n",
    "  optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "  model = CVAE(latent_dim)\n",
    "\n",
    "  for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "    for train_x in train_dataset:\n",
    "      train_step(model, train_x, optimizer)\n",
    "    end_time = time.time()\n",
    "\n",
    "    loss = tf.keras.metrics.Mean()\n",
    "    for test_x in test_dataset:\n",
    "      loss(compute_loss(model, test_x))\n",
    "    elbo = -loss.result()\n",
    "    model.encoder.save(f'{output_path}/{epoch}.encoder')\n",
    "    model.decoder.save(f'{output_path}/{epoch}.decoder')\n",
    "    metrics = {'elbo': float(elbo), 'elapsed': end_time - start_time}\n",
    "    json.dump(metrics, open(f'{output_path}/{epoch}.metrics.json', 'w'))\n",
    "    print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "          .format(epoch, elbo, end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://1c2f27faaa42f41a-dot-us-east1.pipelines.googleusercontent.com//#/experiments/details/b547873f-afb3-4c25-a97d-b0bda5bcf688\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://1c2f27faaa42f41a-dot-us-east1.pipelines.googleusercontent.com//#/runs/details/3989cc5e-c66f-4a23-b73b-9f33c77303bd\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@kfp.dsl.pipeline(name='digit-generator')\n",
    "def pipeline(epochs: int):\n",
    "    load_dataset_task = load_dataset()\n",
    "    train_images = load_dataset_task.outputs['train_images']\n",
    "    test_images = load_dataset_task.outputs['test_images']\n",
    "    train_images = preprocess_images(train_images).output\n",
    "    test_images = preprocess_images(test_images).output\n",
    "    train_task = train(\n",
    "        epochs=epochs, \n",
    "        latent_dim=2, \n",
    "        train_size=60000,\n",
    "        test_size=10000,\n",
    "        batch_size=32,\n",
    "        train_images=train_images,\n",
    "        test_images=test_images)\n",
    "    train_task.add_node_selector_constraint('cloud.google.com/gke-accelerator', 'nvidia-tesla-p100')\n",
    "    train_task.set_gpu_limit(1)\n",
    "    \n",
    "pipeline_arguments = dict(\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "kfp_client = kfp.Client(host='https://1c2f27faaa42f41a-dot-us-east1.pipelines.googleusercontent.com/')\n",
    "run = kfp_client.create_run_from_pipeline_func(\n",
    "    pipeline, \n",
    "    experiment_name='digit-generator',\n",
    "    arguments=pipeline_arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_test_sample(test_images_path, sample_size, output_path):\n",
    "  import numpy as np\n",
    "\n",
    "  test_images = np.load(test_images_path)\n",
    "  np.random.shuffle(test_images)\n",
    "  test_sample = test_images[:sample_size]\n",
    "  np.save(open(output_path, 'wb'), test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(\n",
    "    test_sample_path,\n",
    "    model_path,\n",
    "    output_path):\n",
    "\n",
    "  import numpy as np\n",
    "  import tensorflow as tf \n",
    "\n",
    "  x = np.load(test_sample_path)\n",
    "  encoder = tf.keras.models.load_model(f'{model_path}/encoder')\n",
    "  decoder = tf.keras.models.load_model(f'{model_path}/decoder')\n",
    "  mean, logvar = tf.split(encoder(x), num_or_size_splits=2, axis=1)\n",
    "  z = tf.random.normal(shape=mean.shape) * tf.exp(logvar * .5) + mean\n",
    "  logits = decoder(z)\n",
    "  predictions = tf.sigmoid(logits)\n",
    "  fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'{output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_animation(filenames, output_file):\n",
    "  import imageio\n",
    "\n",
    "  with imageio.get_writer(output_file, mode='I') as writer:\n",
    "    for filename in filenames:\n",
    "      image = imageio.imread(filename)\n",
    "      writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_images(model_path, n, digit_size, output_path):\n",
    "  import matplotlib.pyplot as plt\n",
    "  import numpy as np\n",
    "  import tensorflow as tf\n",
    "  import tensorflow_probability as tfp\n",
    "\n",
    "  decoder = tf.keras.models.load_model(f'{model_path}/decoder')\n",
    "\n",
    "  norm = tfp.distributions.Normal(0, 1)\n",
    "  grid_x = norm.quantile(np.linspace(0.05, 0.95, n))\n",
    "  grid_y = norm.quantile(np.linspace(0.05, 0.95, n))\n",
    "  image_width = digit_size*n\n",
    "  image_height = image_width\n",
    "  image = np.zeros((image_height, image_width))\n",
    "\n",
    "  for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "      z = np.array([[xi, yi]])\n",
    "      logits = decoder(z)\n",
    "      x_decoded = tf.sigmoid(logits)\n",
    "      digit = tf.reshape(x_decoded[0], (digit_size, digit_size))\n",
    "      image[i * digit_size: (i + 1) * digit_size,\n",
    "            j * digit_size: (j + 1) * digit_size] = digit.numpy()\n",
    "\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  plt.imshow(image, cmap='Greys_r')\n",
    "  plt.axis('Off')\n",
    "  plt.savefig(f'{output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data\n",
    "!mkdir -p data/raw\n",
    "!mkdir -p data/processed\n",
    "!mkdir -p data/model\n",
    "!mkdir -p data/generated\n",
    "\n",
    "\n",
    "# epochs = 10\n",
    "# load_dataset(output_path='data/raw')\n",
    "# preprocess_images('data/raw/train-images.npy', 'data/processed/train-images.npy')\n",
    "# preprocess_images('data/raw/test-images.npy', 'data/processed/test-images.npy')\n",
    "# save_test_sample(\n",
    "#     test_images_path='data/processed/test-images.npy',\n",
    "#     sample_size=16,\n",
    "#     output_path='data/sample-images.npy'\n",
    "# )\n",
    "# train(\n",
    "#     epochs=epochs, \n",
    "#     latent_dim=2, \n",
    "#     train_size=60000,\n",
    "#     test_size=10000,\n",
    "#     batch_size=32,\n",
    "#     train_images_path='data/processed/train-images.npy',\n",
    "#     test_images_path='data/processed/test-images.npy',\n",
    "#     output_path='data/model')\n",
    "# for i in range(1, epochs + 1):\n",
    "#   generate_image(\n",
    "#       test_sample_path='data/sample-images.npy',\n",
    "#       model_path=f'data/model/epoch/{i}',\n",
    "#       output_path=f'data/generated/{i}.png'\n",
    "#   )\n",
    "#   plot_latent_images(\n",
    "#       model_path=f'data/model/epoch/{i}', n=20, digit_size=28, \n",
    "#       output_path=f'data/latent.{i}.png')\n",
    "    \n",
    "# create_animation(\n",
    "#   filenames=[f'data/generated/{i}.png' for i in range(1, epochs + 1)],\n",
    "#   output_file='data/cvae.gif'    \n",
    "# )\n",
    "# create_animation(\n",
    "#   filenames=[f'data/latent.{i}.png' for i in range(1, epochs + 1)],\n",
    "#   output_file='data/latent.gif'    \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNEnUNuAC792XG14rDrdU5q",
   "include_colab_link": true,
   "name": "main.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "common-cpu.mnightly-2021-02-12-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:mnightly-2021-02-12-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
