{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "mnist-cnn.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "26897df6-8f8f-4e05-bb30-783c482ce17f"
      },
      "source": [
        "%pip install \\\n",
        "    git+https://github.com/deepmind/dm-haiku@v0.0.4 \\\n",
        "    git+https://github.com/deepmind/optax@v0.0.9 \\"
      ],
      "id": "26897df6-8f8f-4e05-bb30-783c482ce17f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ffc2a1f"
      },
      "source": [
        "# MNIST CNN\n",
        "Based on [dm-haiku/mnist.py](https://github.com/deepmind/dm-haiku/blob/main/examples/mnist.py)"
      ],
      "id": "4ffc2a1f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54f56dca"
      },
      "source": [
        "import haiku as hk\n",
        "\n",
        "import jax\n",
        "from jax import jit, partial, vmap, grad\n",
        "from jax import random\n",
        "import jax.lax as lax\n",
        "import jax.nn as nn\n",
        "import jax.numpy as np\n",
        "\n",
        "import optax\n",
        "\n",
        "import tensorflow_datasets as tfds"
      ],
      "id": "54f56dca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c6af4f7"
      },
      "source": [
        "rng = random.PRNGKey(42)"
      ],
      "id": "1c6af4f7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1df2bd5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20732cad-80d2-47b4-e0a3-585f648eaad6"
      },
      "source": [
        "def ravel_tree(tree):\n",
        "    return np.concatenate(list(map(np.ravel, jax.tree_leaves(tree))))\n",
        "ravel_tree((np.array([1, 2, 3]), np.array([[4, 5], [6, 7]])))"
      ],
      "id": "1df2bd5f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([1, 2, 3, 4, 5, 6, 7], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "702f56c2"
      },
      "source": [
        "train_batch_size = 128\n",
        "eval_batch_size = 1024\n",
        "\n",
        "def load_dataset(split, *, is_training, batch_size):\n",
        "    ds = tfds.load(\"mnist:3.*.*\", split=split).cache().repeat()\n",
        "    if is_training:\n",
        "        ds = ds.shuffle(10 * batch_size, seed=0)\n",
        "    ds = ds.batch(batch_size)\n",
        "    return iter(tfds.as_numpy(ds))\n",
        "train = load_dataset(\"train\", is_training=True, batch_size=train_batch_size)\n",
        "train_eval = load_dataset(\"train\", is_training=False, batch_size=eval_batch_size)\n",
        "test_eval = load_dataset(\"test\", is_training=False, batch_size=eval_batch_size)\n",
        "batch = next(train)\n",
        "batch['image'].shape, batch['label'].shape"
      ],
      "id": "702f56c2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af3a3f5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d3fdf99-ffa4-495d-bcb6-22cf44bfa806"
      },
      "source": [
        "label_count = 10\n",
        "\n",
        "@hk.without_apply_rng\n",
        "@hk.transform\n",
        "def model(batch):\n",
        "    x = batch[\"image\"].astype(np.float32) / 255.\n",
        "    mlp = hk.Sequential([\n",
        "        hk.Conv2D(64, kernel_shape=(3,3)), nn.relu,\n",
        "        hk.Conv2D(32, kernel_shape=(3,3)), nn.relu,\n",
        "        hk.Flatten(),\n",
        "        hk.Linear(label_count),\n",
        "    ])\n",
        "    return mlp(x)\n",
        "print(hk.experimental.tabulate(model, columns=['module', 'input', 'output', 'params_size'])(batch))"
      ],
      "id": "af3a3f5d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------------+-------------------+-------------------+---------------+\n",
            "| Module                     | Input             | Output            |   Param count |\n",
            "+============================+===================+===================+===============+\n",
            "| sequential (Sequential)    | f32[128,28,28,1]  | f32[128,10]       |       269,994 |\n",
            "+----------------------------+-------------------+-------------------+---------------+\n",
            "| conv2_d (Conv2D)           | f32[128,28,28,1]  | f32[128,28,28,64] |           640 |\n",
            "|  └ sequential (Sequential) |                   |                   |               |\n",
            "+----------------------------+-------------------+-------------------+---------------+\n",
            "| conv2_d_1 (Conv2D)         | f32[128,28,28,64] | f32[128,28,28,32] |        18,464 |\n",
            "|  └ sequential (Sequential) |                   |                   |               |\n",
            "+----------------------------+-------------------+-------------------+---------------+\n",
            "| flatten (Flatten)          | f32[128,28,28,32] | f32[128,25088]    |             0 |\n",
            "|  └ sequential (Sequential) |                   |                   |               |\n",
            "+----------------------------+-------------------+-------------------+---------------+\n",
            "| linear (Linear)            | f32[128,25088]    | f32[128,10]       |       250,890 |\n",
            "|  └ sequential (Sequential) |                   |                   |               |\n",
            "+----------------------------+-------------------+-------------------+---------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07adc8aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11b14547-26fd-4a0f-ee5f-4ae2bf322926"
      },
      "source": [
        "def loss(params, batch):\n",
        "    logits = model.apply(params, batch)\n",
        "    labels = nn.one_hot(batch['label'], label_count)\n",
        "    l2_loss = np.sum(optax.l2_loss(ravel_tree(params)))\n",
        "    softmax_xent = optax.softmax_cross_entropy(logits, labels)\n",
        "    softmax_xent = np.mean(softmax_xent)\n",
        "    softmax_xent = softmax_xent + 1e-4 * l2_loss\n",
        "    return softmax_xent\n",
        "rng, r = random.split(rng)\n",
        "weights = average_weights= model.init(r, next(train))\n",
        "loss(weights, batch)"
      ],
      "id": "07adc8aa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(2.3454196, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efd616c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a1df64-df27-464d-a1af-b5a6e4005c4a"
      },
      "source": [
        "@jax.jit\n",
        "def accuracy(weights, batch):\n",
        "    predictions = model.apply(weights, batch)\n",
        "    return np.mean(np.argmax(predictions, axis=-1) == batch[\"label\"])\n",
        "accuracy(weights, batch)"
      ],
      "id": "efd616c6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(0.0234375, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c79404a"
      },
      "source": [
        "optimizer = optax.adam(1e-3)\n",
        "optimizer_state = optimizer.init(weights)"
      ],
      "id": "8c79404a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2f0ebb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec38666c-fc6c-4579-864b-881073fdfd25"
      },
      "source": [
        "@jax.jit\n",
        "def update(weights, optimizer_state, batch):\n",
        "    loss_grads = grad(loss)(weights, batch)\n",
        "    optimizer_updates, optimizer_state = optimizer.update(loss_grads, optimizer_state)\n",
        "    weights = optax.apply_updates(weights, optimizer_updates)\n",
        "    return weights, optimizer_state\n",
        "np.mean(np.abs(ravel_tree(update(weights, optimizer_state, batch)[0])))"
      ],
      "id": "e2f0ebb7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(0.00672121, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a874ba5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9ec972a-0467-4df8-89b3-3176f564c7d8"
      },
      "source": [
        "@jit\n",
        "def ema_update(weights, average_weights):\n",
        "    return optax.incremental_update(weights, average_weights, step_size=0.001)\n",
        "np.mean(np.abs(ravel_tree(ema_update(weights, average_weights))))"
      ],
      "id": "a874ba5f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(0.0068145, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "d275d27a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b88aaee-b71b-42f5-ab5c-ee3e2c03fce4"
      },
      "source": [
        "for step in range(2000):\n",
        "    if step % 100 == 0:\n",
        "        train_accuracy = accuracy(average_weights, next(train_eval))\n",
        "        test_accuracy = accuracy(average_weights, next(test_eval))\n",
        "        print(f\"[Step {step}] Train / Test accuracy: {train_accuracy:.3f} / {test_accuracy:.3f}.\")\n",
        "\n",
        "    weights, optimizer_state = update(weights, optimizer_state, next(train))\n",
        "    average_weights = ema_update(weights, average_weights)"
      ],
      "id": "d275d27a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Step 0] Train / Test accuracy: 0.071 / 0.061.\n",
            "[Step 100] Train / Test accuracy: 0.707 / 0.693.\n",
            "[Step 200] Train / Test accuracy: 0.893 / 0.887.\n",
            "[Step 300] Train / Test accuracy: 0.921 / 0.921.\n",
            "[Step 400] Train / Test accuracy: 0.940 / 0.951.\n",
            "[Step 500] Train / Test accuracy: 0.962 / 0.960.\n",
            "[Step 600] Train / Test accuracy: 0.971 / 0.972.\n",
            "[Step 700] Train / Test accuracy: 0.978 / 0.978.\n",
            "[Step 800] Train / Test accuracy: 0.981 / 0.977.\n",
            "[Step 900] Train / Test accuracy: 0.980 / 0.979.\n",
            "[Step 1000] Train / Test accuracy: 0.988 / 0.979.\n",
            "[Step 1100] Train / Test accuracy: 0.985 / 0.988.\n",
            "[Step 1200] Train / Test accuracy: 0.995 / 0.981.\n",
            "[Step 1300] Train / Test accuracy: 0.990 / 0.979.\n",
            "[Step 1400] Train / Test accuracy: 0.990 / 0.984.\n",
            "[Step 1500] Train / Test accuracy: 0.995 / 0.987.\n",
            "[Step 1600] Train / Test accuracy: 0.994 / 0.985.\n",
            "[Step 1700] Train / Test accuracy: 0.997 / 0.991.\n",
            "[Step 1800] Train / Test accuracy: 0.998 / 0.987.\n",
            "[Step 1900] Train / Test accuracy: 0.995 / 0.989.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}